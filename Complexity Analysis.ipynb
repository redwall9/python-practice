{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d501a0a8",
   "metadata": {},
   "source": [
    "First, see if you can figure out what the following code does. I suggest creating a small sample list and choosing target to be some value, and then tracing out the execution of the progam on a piece of paper. When you're ready, scroll down for the answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "585c5aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "\n",
    "# nums is a sorted list of integers\n",
    "# target is an integer\n",
    "def magic(nums, target):\n",
    "    start = 0\n",
    "    end = len(nums) - 1\n",
    "    while (start <= end):\n",
    "        mid = math.floor((start + end) / 2)\n",
    "        if (nums[mid] == target):\n",
    "            return True\n",
    "        elif (nums[mid] > target):\n",
    "            end = mid - 1\n",
    "        else:\n",
    "            start = mid + 1\n",
    "\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8393725e",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br><br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "The function above implements binary search - given a sorted list of integers, it is possible to determine if a target value is present in the list faster than iterating over every value and checking if it is the right one. Instead, we can start from the middle, and if the value at that position is larger than our target, we know that the target, if present, must be in the left half of the list. So, we repeat this process on the left half of the list, choosing to inspect the index that is halfway between the start and the previous index that we inspected. Similarly, if the value at the current position is smaller than our target, then we know that our target is in the right half of the (remaining) list. In this way, one each iteration of the loop we can halve the number of values that we are looking at, until we eventually reach a single value left, that will either be our target or not. \n",
    "\n",
    "Let's add some print statements to see how this program behaves when given an example list and target value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b43a1206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start: 0, End: 15, Mid: 7, Current Value: 7\n",
      "Start: 0, End: 6, Mid: 3, Current Value: 3\n",
      "Start: 4, End: 6, Mid: 5, Current Value: 5\n",
      "Start: 4, End: 4, Mid: 4, Current Value: 4\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import math \n",
    "\n",
    "def bsearch_with_prints(nums, target):\n",
    "    start = 0\n",
    "    end = len(nums) - 1\n",
    "    while (start <= end):\n",
    "        mid = math.floor((start + end) / 2)\n",
    "        \n",
    "        print(\"Start: {}, End: {}, Mid: {}, Current Value: {}\".format(start, end, mid, nums[mid]))\n",
    "        \n",
    "        if (nums[mid] == target):\n",
    "            return True\n",
    "        elif (nums[mid] > target):\n",
    "            end = mid - 1\n",
    "        else:\n",
    "            start = mid + 1\n",
    "\n",
    "    return False\n",
    "\n",
    "print(bsearch_with_prints([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80cfa10",
   "metadata": {},
   "source": [
    "For simplicity, I chose the values in the array to be equal to their index, but that doesn't need to be the case. Here, we inspect index `7` first, and since our target, `4`, is less than `7`, we restrict the range of indices that we want to look at to `[0, 6]`. Halfway through that range is index `3` - `4` is greater than `3`, so we move to the right this time, restricting our range to `[4,6]`. We repeat until we eventually find that `4` is in the list.\n",
    "\n",
    "How many values would we need to inspect in the worst case? The answer is `log_2(len(nums))`, which in this case is `log_2(16) = 4`. The reason for this is because on every iteration we cut the list in half, and in the worst case we must do this until there is only one element left to consider. The number of times that an integer can be cut in half is given by `log_2(n)` (plus or minus 1, but that isn't important, for reasons I'll explain later). \n",
    "\n",
    "This idea of calculating how long an algorithm will take in the worst case is called complexity analysis, and is represented using Big-O notation. Big-O notation tells us, mathematically, how long we expect a function to take given the size of the function's inputs. In this case, we would say that the Big-O complexity of binary search is `O(log(n))`, where `n` is the size of the input list. The value that the Big-O represents is always some measure of the number of fundamental operations the algorithm has to perform - in this case, the operation we consider is the number of comparisons; that is, how many times we need to compare our target value against some value in the list? Number of comparisons is a common operation that is used for complexity analysis, but anything can be used, depending on what makes sense for the algorithm being analyzed.\n",
    "\n",
    "(Additional note: in Big-O notation, constant factors are omitted, which is why I've turned `log_2` into just `log`. Every logarithm can be converted to a different base by multiplying by some constant factor, so computer scientists just omit the base altogether in complexity analysis. You may have also noticed that on every iteration of the loop we actually make two comparisons - one for equality and one for greater than. So the number of comparisons we make in the worst case is actually `2*log_2(n)`. But as I mentioned before, constant factors don't matter, so we drop the `2` in front as well).\n",
    "\n",
    "We also like to talk about how fast an algorithm is in its best and average cases as well. For binary search, the best case is that the first value we look at just happens to be the correct one. This is represented by `O(1)`, which means the algorithm operates in _constant_ time. One confusing this here is that the `1` doesn't necessarily mean that it took only operation for the algorithm to complete, it just means that it took a _constant_ number of operations that is _independent_ of the size of the input, since as we mentioned before all that constant factors are considered equal in complexity analysis. In this implementation that happens to be one operation, but that doesn't need to be the case. \n",
    "\n",
    "In turns out that binary search's average complexity is also `O(log(n))`. Proving that rigorously is not as straightforward as you might think, and frankly, it's not a particularly important exercise. As long as you intuitively understand that on average you'll make about that many comparisons when running binary search on an arbitrary list with an arbitrary target, that's good enough."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c1228c",
   "metadata": {},
   "source": [
    "Let's switch gears for a minute and talk about another programming problem called the `Two Sum Problem`. In this problem, we're given a sorted list of integers, and asked to determine if there are two values in the list that add up to a specified target. The _brute force_ solution is two try every single pair of values possible and see if one works. This can be achieved by writing two for loops as follows. Note that I've chosen the target value in all of the following examples to purposely be impossible to demonstrate the worst-case execution time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b97734e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "Function took 5959.336280822754 milliseconds to run!\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import random\n",
    "import time\n",
    "\n",
    "def twosum_v1(nums, target):\n",
    "    for i in range(len(nums)):\n",
    "        for j in range(i+1, len(nums)):\n",
    "            if (nums[i] + nums[j] == target):\n",
    "                return True\n",
    "\n",
    "    return False\n",
    "\n",
    "# generate a list of 10,000 random numbers.\n",
    "nums = random.choices(range(1, 10000000), k = 10000)\n",
    "nums.sort()\n",
    "target = 0\n",
    "\n",
    "# time how long it takes to run our function on this random list\n",
    "start = time.time()\n",
    "\n",
    "print(twosum_v1(nums, target))\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"Function took {} milliseconds to run!\".format((end - start) * 1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e0bd56",
   "metadata": {},
   "source": [
    "If you run the above code, you should see that it takes several seconds - this is very slow. Let's think about the `Big-O` for a second. What basic operation should we use for our analysis? Here, a good choice seems to be how many pairs of values we need to check before the algorithm completes. In this brute force approach, we have to consider `n^2` pairs of values, where `n` is again the length of the list (size of the input). So our algorithm is `O(n^2)`.\n",
    "\n",
    "`Big-O` notation is all relative - a particular complexity could be completely awful for solving one problem, but be the best that can be done for another problem. In this case, we can do better than `O(n^2)`.\n",
    "\n",
    "Think about our original algorithm - we're running two loops that go through every single possible pair. Consider the following observation - when we go through every iteration of the outer loop, we know one value that will be in the pair we are checking. At that point, we can actually compute the necessary value for the other number in the pair as `second_num = target - first_num`. Now if only we had a way to search for a number in a sorted list ... which we do! We implemented binary search earlier. Let's make use of that algorithm we wrote earlier to speed up our solution to the `Two Sum Problem`. (Note that I've slightly modified our binary search implementation to take initial start and end indices as function arguments - that's so that we can specify which part of the list we want to look at)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1296a5d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "Function took 60.350656509399414 milliseconds to run!\n"
     ]
    }
   ],
   "source": [
    "import math \n",
    "import random\n",
    "import time\n",
    "\n",
    "# nums is a sorted list of integers\n",
    "# target is an integer\n",
    "def bsearch(nums, start, end, target):\n",
    "    while (start <= end):\n",
    "        mid = math.floor((start + end) / 2)\n",
    "        if (nums[mid] == target):\n",
    "            return True\n",
    "        elif (nums[mid] > target):\n",
    "            end = mid - 1\n",
    "        else:\n",
    "            start = mid + 1\n",
    "\n",
    "    return False\n",
    "\n",
    "def twosum_v2(nums, target):\n",
    "    for i in range(len(nums)):\n",
    "        found = bsearch(nums, i+1, len(nums)-1, target - nums[i])\n",
    "        if (found):\n",
    "            return True\n",
    "\n",
    "    return False\n",
    "\n",
    "# generate a list of 10,000 random numbers.\n",
    "nums = random.choices(range(1, 10000000), k = 10000)\n",
    "nums.sort()\n",
    "target = 0\n",
    "\n",
    "# time how long it takes to run our function on this random list\n",
    "start = time.time()\n",
    "\n",
    "print(twosum_v2(nums, target))\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"Function took {} milliseconds to run!\".format((end - start) * 1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea9726f",
   "metadata": {},
   "source": [
    "When you run our new version of the code, it takes well under a second to run, which is way faster! Let's analyze the complexity. We have to loop through the list once to get the first value in each pair - that's `O(n)`. To find the second value in each pair, we run a binary search on the list, which results in us checking `log(n)` values. Overall, that means we have to check `O(n*log(n))` pairs, which, if you make a graph, is much less than `O(n^2)` for sufficiently large values of `n`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f482c3a3",
   "metadata": {},
   "source": [
    "Can we do even better though? It turns out that we can! Our fundamental observation in going from our first to our second solution was to realize that we could utilize the fact that the list is sorted to reduce the number of pairs that we need to check. In order to further reduce the number of pairs that we look at, we're going to need to make a slightly trickier observation. Let's say that the first pair that we check consists of the very first and last value in the list. If the sum of those values is bigger than the target, then we need to make the sum smaller. The first value in the pair can't get smaller - it's already the smallest in the list. That means the next pair we should check is the first value and the second to last value. Similarly, what if the sum of those values was smaller than our target? In that case, we need to make the first value bigger (the second one can't get any bigger). We repeat this process until we find a suitable pair, or none exists, which results in us meeting somewhere in the middle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2300995d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "Function took 2.321958541870117 milliseconds to run!\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import random \n",
    "import time\n",
    "\n",
    "def twosum_v3(nums, target):\n",
    "    left = 0\n",
    "    right = len(nums) - 1\n",
    "    while (left < right):\n",
    "        test = nums[left] + nums[right]\n",
    "        if (test == target):\n",
    "            return True\n",
    "        elif (test > target):\n",
    "            right = right - 1\n",
    "        else:\n",
    "            left = left + 1\n",
    "\n",
    "    return False\n",
    "\n",
    "# generate a list of 10,000 random numbers.\n",
    "nums = random.choices(range(1, 10000000), k = 10000)\n",
    "nums.sort()\n",
    "target = 0\n",
    "\n",
    "# time how long it takes to run our function on this random list\n",
    "start = time.time()\n",
    "\n",
    "print(twosum_v3(nums, target))\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"Function took {} milliseconds to run!\".format((end - start) * 1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d20318d",
   "metadata": {},
   "source": [
    "And this solution is even faster than the last one! The complexity of this solution is `O(n)`, since we only ever check `n` pairs of values in the worst case. (Again, `n` is the length of the list)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc062807",
   "metadata": {},
   "source": [
    "When computer scientists analyze performance, `Big-O` is always the first thing we look at. However, those constant factors that I mentioned before that we drop do sometimes matter! So far, our algorithms worked if the list had both positive and negative numbers. What if we added another restriction that our list only has non-negative numbers? Here's one example where we can make a further optimization to our last solution to catch the fact that our target, `0`, definitely isn't in the list faster than we noticed with our previous solution. \n",
    "\n",
    "Let's consider the pair we're testing at any given point in time, `(nums[left], nums[right])`. If `target < nums[left]`, then we already know for sure that it's impossible for a suitable pair to exist - mathematically, every remaining pair must have a sum larger than the target. Similarly, if `target > 2 * nums[right]`, we also know that there is no suitable pair, since no future pair can have a sum greater than the target. Let's implement these optimizations and see what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cda107dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "Function took 0.1704692840576172 milliseconds to run!\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import random \n",
    "import time\n",
    "\n",
    "def twosum_v4(nums, target):\n",
    "    left = 0\n",
    "    right = len(nums) - 1\n",
    "    while (left < right):\n",
    "        test = nums[left] + nums[right]\n",
    "        if (target < nums[left]):\n",
    "            return False\n",
    "        elif (target > 2 * nums[right]):\n",
    "            return False\n",
    "        elif (test == target):\n",
    "            return True\n",
    "        elif (test > target):\n",
    "            left = left + 1\n",
    "        else:\n",
    "            right = right - 1\n",
    "\n",
    "    return False\n",
    "\n",
    "# generate a list of 10,000 random numbers.\n",
    "nums = random.choices(range(1, 10000000), k = 10000)\n",
    "nums.sort()\n",
    "target = 0\n",
    "\n",
    "# time how long it takes to run our function on this random list\n",
    "start = time.time()\n",
    "\n",
    "print(twosum_v4(nums, target))\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"Function took {} milliseconds to run!\".format((end - start) * 1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83ce91c",
   "metadata": {},
   "source": [
    "With this additional constraint, this new set of optimizations handles some extra corner cases that our previous one didn't, resulting in faster performance for those special cases. Our `Big-O` complexity might not care about such a change, but it does improve our real life performance, which is important as well. (Try and think about why we had to add the restriction that the numbers are non-negative - can you create a list that contains negative numbers where these new optimizations would cause the algorithm to fail?)\n",
    "\n",
    "Hopefully this helped explain complexity analysis a little bit, and how programmers approach a problem. Almost always, the best way to do this is to think of the easiest possible solution, and then see if there's a way to tweak it slightly so that the complexity improves. Repeat this until you think you have something that is as good as it will get. Or even better, intuitively / mathematically prove that you can't do any better."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
